"""
URL Dataset Downloader
Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§Ø³Øª Ø§Ø² Ø¢Ø¯Ø±Ø³ Ø§ÛŒÙ†ØªØ±Ù†ØªÛŒ
"""
import requests
import json
import csv
import os
from backend.core.fox_learning import FoxLearningSystem
from backend.core.user_profiles import user_manager

class URLDatasetDownloader:
    def __init__(self):
        self.data_dir = "data/url_datasets"
        self.ensure_data_dir()
        
    def ensure_data_dir(self):
        os.makedirs(self.data_dir, exist_ok=True)
        
    def download_from_url(self, url):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ø² URL"""
        print(f"ðŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø²: {url}")
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            return response.text
            
        except Exception as e:
            raise Exception(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯: {str(e)}")
            
    def parse_dataset(self, content, url):
        """ØªØ¬Ø²ÛŒÙ‡ Ø¯ÛŒØªØ§Ø³Øª"""
        print("ðŸ” ØªØ¬Ø²ÛŒÙ‡ Ø¯ÛŒØªØ§Ø³Øª...")
        
        data = []
        
        try:
            # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ Ø§Ø² URL
            if url.endswith('.json'):
                data = self.parse_json(content)
            elif url.endswith('.csv'):
                data = self.parse_csv(content)
            elif url.endswith('.txt'):
                data = self.parse_txt(content)
            else:
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ JSON
                try:
                    data = self.parse_json(content)
                except:
                    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ CSV
                    try:
                        data = self.parse_csv(content)
                    except:
                        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ TXT
                        data = self.parse_txt(content)
                        
        except Exception as e:
            raise Exception(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¬Ø²ÛŒÙ‡: {str(e)}")
            
        return data
        
    def parse_json(self, content):
        """ØªØ¬Ø²ÛŒÙ‡ JSON"""
        json_data = json.loads(content)
        
        conversations = []
        
        # ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù JSON
        if isinstance(json_data, list):
            for item in json_data:
                if isinstance(item, dict):
                    # ÙØ±Ù…Øª {"question": "...", "answer": "..."}
                    if "question" in item and "answer" in item:
                        conversations.append({
                            "q": item["question"],
                            "a": item["answer"]
                        })
                    # ÙØ±Ù…Øª {"q": "...", "a": "..."}
                    elif "q" in item and "a" in item:
                        conversations.append(item)
                    # ÙØ±Ù…Øª {"input": "...", "output": "..."}
                    elif "input" in item and "output" in item:
                        conversations.append({
                            "q": item["input"],
                            "a": item["output"]
                        })
                        
        elif isinstance(json_data, dict):
            # ÙØ±Ù…Øª {"conversations": [...]}
            if "conversations" in json_data:
                return self.parse_json(json.dumps(json_data["conversations"]))
            # ÙØ±Ù…Øª {"data": [...]}
            elif "data" in json_data:
                return self.parse_json(json.dumps(json_data["data"]))
                
        return conversations
        
    def parse_csv(self, content):
        """ØªØ¬Ø²ÛŒÙ‡ CSV"""
        conversations = []
        
        lines = content.strip().split('\n')
        reader = csv.reader(lines)
        
        headers = next(reader, None)
        if not headers:
            return conversations
            
        for row in reader:
            if len(row) >= 2:
                conversations.append({
                    "q": row[0].strip(),
                    "a": row[1].strip()
                })
                
        return conversations
        
    def parse_txt(self, content):
        """ØªØ¬Ø²ÛŒÙ‡ TXT"""
        conversations = []
        
        lines = content.strip().split('\n')
        
        for i in range(0, len(lines)-1, 2):
            if i+1 < len(lines):
                q = lines[i].strip()
                a = lines[i+1].strip()
                
                if q and a:
                    conversations.append({
                        "q": q,
                        "a": a
                    })
                    
        return conversations
        
    def save_to_fox(self, data, url):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù…ØºØ² Fox"""
        print("ðŸ§  Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù…ØºØ² Fox...")
        
        profile = user_manager.get_current_user_profile()
        fox_learning = FoxLearningSystem(profile)
        
        saved_count = 0
        
        for item in data:
            try:
                if "q" in item and "a" in item:
                    fox_learning.teach_response(item["q"], item["a"])
                    saved_count += 1
                    
                    if saved_count % 10 == 0:
                        print(f"âœ… {saved_count} Ù…Ú©Ø§Ù„Ù…Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯...")
                        
            except Exception as e:
                continue
                
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
        filename = url.split('/')[-1] or "dataset"
        json_file = os.path.join(self.data_dir, f"{filename}.json")
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        print(f"ðŸŽ‰ {saved_count} Ù…Ú©Ø§Ù„Ù…Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!")
        print(f"ðŸ“ ÙØ§ÛŒÙ„: {json_file}")
        
        return saved_count
        
    def download_and_process(self, url):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„"""
        try:
            # Ø¯Ø§Ù†Ù„ÙˆØ¯
            content = self.download_from_url(url)
            
            # ØªØ¬Ø²ÛŒÙ‡
            data = self.parse_dataset(content, url)
            
            if not data:
                return {"error": "Ù‡ÛŒÚ† Ù…Ú©Ø§Ù„Ù…Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯"}
                
            # Ø°Ø®ÛŒØ±Ù‡
            saved_count = self.save_to_fox(data, url)
            
            return {
                "success": True,
                "downloaded": len(data),
                "saved": saved_count,
                "url": url
            }
            
        except Exception as e:
            return {"error": str(e)}

# Global instance
url_downloader = URLDatasetDownloader()
